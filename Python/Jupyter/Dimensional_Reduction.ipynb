{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold; font-size: 2rem; padding-top: 20px; margin: 20px 0; border-top: 2px solid #000;\">\n",
    "    Section 1.1: Dimensionality Reduction\n",
    "</div>\n",
    "<div style=\"font-size: 1.5rem; line-height: 2.5rem; padding-bottom: 30px;\">\n",
    "    Purpose: reduces amount of time and memory required by algorithms/eliminate noise<br/>\n",
    "    (Transformations/Mathmatics) Linear (PCA/SVD) or non-linear (t-SNE) && Supervised or unsupervised<br/><br/>\n",
    "    <b>Principle Component Analysis</b>:<br/>\n",
    "    Goal is to find a projection that captures the <i>largest amount of variation in data</i>. Such a projection of the data also best represents the data in the <i>least square sense</i> \n",
    "</div>\n",
    "\n",
    "${\\displaystyle{\n",
    "    min ||x - \\hat{x}||^2 \\\\\n",
    "    \\text{where }\\hat{x}\\text{ is the approximation of x}\n",
    "}}$\n",
    "\n",
    "<div style=\"padding-top: 15px;\">\n",
    "    Goal is to capture the axis with most variation, therefore showing the most important axis (principle axis) or, most important variable in the data.<br/>\n",
    "    Only gain from PCA if there is a strong correlation in the attributes (values)<br/>\n",
    "    <ul>Steps to PCA\n",
    "        <li>Find eigenvectors of the sample covariance matrix using the given data</li>\n",
    "        <li>Eigenvectors define the new space</li>\n",
    "    </ul><br/>\n",
    "    <ul>PCA Basics\n",
    "        <li>take n variables and find linear combination of variables to produce a new set of variables that are\n",
    "            uncorrelated</li>\n",
    "        <li>Order in such a way that the new set is indexed such that y<sub>1</sub> has more variation than y<sub>2</sub> etc.\n",
    "        </li>\n",
    "        <li>Note: aka, Karhunen-Loeve transform, Hotelling transform, or eigenvalue analysis</li>\n",
    "    </ul><br/>\n",
    "</div>\n",
    "\n",
    "${\\displaystyle{\n",
    "    \\text{Start with n-dimensional N data vectors} \\\\\n",
    "    x_1,x_2, \\ldots , x-N \\\\\n",
    "    \\text{use linear transformation to obtain principle componenets for} \\\\\n",
    "    y_i = A(x_i - M_x) \\text{ for } i = 1, N \\\\\n",
    "    \\text{where } m_x = \\frac{1}{N} \\sum_{k=1}^{N}x_k, \\\\ \n",
    "    \\text{ and A is a matrix whose rows are formed from the eigenvectors of the sample coveariance matrix}\n",
    "    \\text{Sample: } \\\\\n",
    "    C_x = \\frac{1}{N-1} \\sum_{k=1}^{N}(x_k - m_x)(x_k - m_x)^t \\\\\n",
    "    c_{pp} = \\sigma^2_{pp} = \\frac{\\sum_i(x_{p_i}-m_{x_p})(x_{p_i} - m_{x_p})}{N - 1} \\\\\n",
    "    c_{pq} = \\sigma_p\\sigma_q = \\frac{\\sum_i(x_{p_i}-m_{x_p})(x_{q_i} - m_{x_q})}{N - 1} \\\\\n",
    "    \\text{mean square error} = e_{mse}  = \\sum_{j = P + 1}^n \\lambda_j  \\\\\n",
    "    \\text{P accounting for data variability for first p eigen values} = P = \\frac{\\sum_{j=1}^p \\lambda_j}{\\sum_{j=1}^n \\lambda_j} \\\\\n",
    "    \\text{Reminder: only use PCA when there's high correlation between attributes}\n",
    "}}$\n",
    "\n",
    "\n",
    "<div style=\"padding-top: 15px; padding-bottom: 30px;\">\n",
    "    To calculate the values for PCA use thee <a href=\"https://stattrek.com/matrix-algebra/covariance-matrix.aspx\">Sample Covariance Matrix</a><br/>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Example\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[7,4,3], [4,1,8],[6,3,5],[8,6,1],[8,5,7],[7,2,9],[5,3,3],[9,5,8],[7,4,5],[8,2,2]])\n",
    "Xmean = np.mean(X, 0)\n",
    "C = np.cov(X.T)\n",
    "w,v = LA.eig(C)\n",
    "A = np.array([v[:,2],v[:,1]])\n",
    "Y = np.matmul(A, (X-Xmean).T)\n",
    "xhat = np.matmul(A.T, Y).T + Xmean\n",
    "mse = np.sum((X- xhat)**2) / 10\n",
    "\n",
    "# print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot for above\n",
    "plt.figure(figsize=(12,6))\n",
    "bw = .1\n",
    "r1 = np.arange(len(xhat))\n",
    "r2 = [x + bw for x in r1]\n",
    "r3 = [x + bw for x in r2]\n",
    "r4 = [x + bw for x in r3]\n",
    "r5 = [x + bw for x in r4]\n",
    "r6 = [x + bw for x in r5]\n",
    "\n",
    "# col 1\n",
    "plt.bar(r1, X[:,0], bw, alpha=.5, color='r', label='original')\n",
    "plt.bar(r2, xhat[:,0], bw, alpha=.5, color='g', label='reconstructed')\n",
    "\n",
    "# col 2\n",
    "plt.bar(r3, X[:,1], bw, alpha=.5, color='r')\n",
    "plt.bar(r4, xhat[:,1], bw, alpha=.5, color='g')\n",
    "\n",
    "# col 3\n",
    "plt.bar(r5, X[:,2], bw, alpha=.5, color='r')\n",
    "plt.bar(r6, xhat[:,2], bw, alpha=.5, color='g')\n",
    "plt.xticks([r + bw for r in range(len(xhat))], ['A','B','C','D','E','F','G','H','I','J'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 1.5rem; line-height: 2.5rem;\">\n",
    "    Eigenvector matrix F for SVD\n",
    "</div>\n",
    "\n",
    "${\\displaystyle{\n",
    "    F = \\sum_{j=1}^r \\lambda_j^{\\frac{1}{2}}u_jv_j^t \\\\\n",
    "    V = F^tF = \\text{ matrix transpose * original} \\\\\n",
    "    U = FF^t = \\text{ matrix * its transpose}\\\\ \n",
    "    \\text{Common definition of norm: Frobenius Norm} \\\\\n",
    "    ||F||_{FNorm} = \\sum_i\\sum_jf_{ij}^2 \\\\\n",
    "    \\text{Frobenius norm from SVD} \\\\\n",
    "    ||F||_{FNorm} = \\sum_i\\lambda_i^2 \\\\\n",
    "    \\text{approximation of F} \\\\\n",
    "    \\hat{F} = \\sum_{j=1}^k \\lambda_j^{\\frac{1}{2}}u_jv_j^t\\text{, where k}\\leq r \\\\\n",
    "    \\text{Error approx as}\\\\\n",
    "    \\epsilon^2 = \\sum_{i=1}^m\\sum_{j=1}^n |f(i,j) - \\hat{f}(i,j)|^2 \\\\\n",
    "    \\epsilon^2 = \\sum_{p = k + 1}^r \\lambda_p\n",
    "}}$\n",
    "\n",
    "<div style=\"padding-top: 15px; padding-bottom: 30px; border-bottom: 2px solid #000;\">\n",
    "    <b>Summary PCA:</b><br/>\n",
    "    May or may not give good results on classification because it doesnt take into acccount class separability, \n",
    "    unsupervised<br/>\n",
    "    Fisher's discriminat function (supervised PCA), used with class labels<br/>\n",
    "    Only used for linear, use Kernel PCA for nonlinear<br/>\n",
    "    Normalize data before applying PCA when different features have different scales\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"font-weight: bold; font-size: 2rem; padding-top: 20px; margin: 20px 0; border-top: 2px solid #000;\">\n",
    "    Section 1.2: Dimensionality reduction via feature subset selection\n",
    "</div>\n",
    "<div style=\"font-size: 1.5rem; line-height: 2.5rem; padding-bottom: 30px;\">\n",
    "    select subset of k features out of n original features.\n",
    "</div>\n",
    "\n",
    "${\\displaystyle{\n",
    "    \\text{total features: } =  \\frac{n!}{k!}(n-k)!\n",
    "}}$\n",
    "\n",
    "\n",
    "<div style=\"padding-top: 15px; padding-bottom: 30px;\">\n",
    "    <b>Evaluating Subsets</b><br/>\n",
    "    Use a measure incorporating class discrimination because class separation is our ultimate aim<br/>\n",
    "    Divergence and Scatter matrices based measures<br/><br/>\n",
    "    <b>Entropy and Divergence</b><br/>\n",
    "    Entropy is a measure of uncertainty<br/>\n",
    "    An event with n possible outcomes with p<sub>i</sub> being the probability of the i-th outcome.<br/>\n",
    "    The entropy H of the event is then define as:\n",
    "</div>\n",
    "\n",
    "${\\displaystyle{\n",
    "    H \\varpropto - \\sum_{i=1}^n p_i \\log p_i = \\sum_{i=1}^n p_i \\log \\frac{1}{p_i} \\\\\n",
    "}}$\n",
    "\n",
    "<div style=\"padding-top: 15px; padding-bottom: 30px;\">\n",
    "    <b>Kullback and Leibler Divergence (KL)</b><br/>\n",
    "    In mathematical statistics, the Kullback–Leibler divergence, is a measure of how one \n",
    "    probability distribution is different from a second, reference probability distribution.<br/><br/>\n",
    "    <b>Scatter Matricies</b><br/>\n",
    "</div>\n",
    "\n",
    "${\\displaystyle{\n",
    "    \\text{Class scatter matrix} \\\\\n",
    "    S_j = \\sum_{x_i \\in c_j} ()\n",
    "}}\n",
    "\n",
    "<!-- Template for sections -->\n",
    "<!-- <div style=\"font-weight: bold; font-size: 2rem; padding-top: 20px; margin: 20px 0; border-top: 2px solid #000;\">\n",
    "    Section x:\n",
    "</div>\n",
    "<div style=\"font-size: 1.5rem; line-height: 2.5rem; padding-bottom: 30px; border-bottom: 2px solid #000;\">\n",
    "</div> -->\n",
    "\n",
    "<!-- template for inbetween latex  -->\n",
    "<!-- <div style=\"padding-top: 15px;\"></div> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
