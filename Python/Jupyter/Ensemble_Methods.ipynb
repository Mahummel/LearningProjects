{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method\n",
    "\n",
    "Train multiple learners for same task, aka <i>committee-based, multiple classifier systems</i>\n",
    "\n",
    "#### Homogeneous/Heterogeneous\n",
    "\n",
    "Homogeneous: all have base learners of same type (e.g. all decision trees)\\\n",
    "Heterogeneous: use a variety\\\n",
    "note: base learners are known as <i>weak</i> learners due to performance only slightly better than random guess\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "<i>Bootstrap aggregrating</i>\\\n",
    "uses bootstrap sampling or sampling with replacement\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample: [1, 2, 15, 2, 15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "data = [1,2,5,7,9,11,13,15,18]\n",
    "sample1 = resample(data, replace=True, n_samples=5, random_state=11)\n",
    "print('Bootstrap sample: {}'.format(sample1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given m training examples, the probability that the ith example is selected k times is approximated by Poisson distribution with $\\lambda = 1$\n",
    "\n",
    "$p(k,\\lambda) = \\frac{e^{-\\lambda}\\lambda^k}{k!} = 0, 1, 2, \\ldots $\n",
    "\n",
    "If a learner is susceptible to additional or deletion of training examples, these are called <i>unstable learners</i>\\\n",
    "Learners such as k-NN are hardly affected by some additions/deletions therefore are known as <i>stable learners</i>\\\n",
    "Bagging works best with <strong><i>Unstable Learners</i></strong> (decision trees, etc)\n",
    "\n",
    "#### Random Forest\n",
    "\n",
    "Extension of bagging with decision trees. In addition to bootstrap sampling,\\\n",
    "a random subset of features are used to select splits from each tree node.\n",
    "sklearn.ensemble: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">RandomForestClassifier</a>\n",
    "\n",
    "#### Boosting\n",
    "\n",
    "Any procedure that combines many weak learners to yield a much higher performance. Base learners in boosting are\\\n",
    "sequentially generated by focusing on examples misclassified by earlier weak learners in the chain.\n",
    "\n",
    "Assign weights to each training example, sets probability of being chosen by next base learner\\\n",
    "Have identical weights initially, as misclassifications occur, increase the weight\\\n",
    "Outputs of learners are combined using the weights to create final response.\n",
    "\n",
    "#### Combining Weak Learners\n",
    "\n",
    "Averaging, voting, stacking\\\n",
    "stacking: combine the output of weak learners, aka <i>second-level learner</i> weak learners: <i>first-level</i>\n",
    "\n",
    "#### Gradient Boosted Trees (GBT)\n",
    "\n",
    "<ol>\n",
    "    <li>Construct base tree with root node: initial guess for all samples</li>\n",
    "    <li>Build a tree from errors of previous tree</li>\n",
    "    <li>Scale the tree by learning rate, learning rate determines the contribution of tree in prediction</li>\n",
    "    <li>Combine the new tree with all previous trees to predict result and repeat step 2 until max tree are achieved, or new \n",
    "        dont fit</li>\n",
    "    <li>Final predicition model is combination of all the trees</li>\n",
    "</ol>\n",
    "\n",
    "Documentation on XGBoosT <a href=\"https://xgboost.ai\">here</a>\\\n",
    "Variation of GBT, fast and highly accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
